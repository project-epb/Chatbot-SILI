/**
 * çœ‹çœ‹ç¾¤å‹ä»¬éƒ½èŠäº†ä»€ä¹ˆå‹¾å…«.jpg
 * @author dragon-fish
 * @license MIT
 */
import { Context, Session, Time, arrayBufferToBase64 } from 'koishi'

import crypto from 'node:crypto'
import { readFileSync, writeFileSync } from 'node:fs'
import { readFile } from 'node:fs/promises'
import { resolve } from 'node:path'

import BasePlugin from '~/_boilerplate'

import { getUserNickFromSession } from '$utils/formatSession'
import { safelyStringify } from '$utils/safelyStringify'
import { ClientOptions, OpenAI } from 'openai'
import { CompletionUsage } from 'openai/resources'

declare module 'koishi' {
  export interface Tables {
    openai_chat: OpenAIConversationLog
  }
  export interface User {
    openai_last_conversation_id: string
  }
}

interface OpenAIConversationLog {
  id: number
  conversation_id: string
  conversation_owner: number
  role: 'system' | 'user' | 'assistant'
  content: string
  usage?: CompletionUsage
  time: number
}

export interface Config {
  openaiOptions: ClientOptions
  model: string
  maxTokens: number
  recordsPerChannel: number
}

export default class PluginOpenAi extends BasePlugin {
  static inject = ['html', 'database']

  openai: OpenAI
  openaiOptions: ClientOptions
  SILI_PROMPT = PluginOpenAi.readPromptFile('SILI-v2.md')
  CHAT_SUMMARY_PROMPT = PluginOpenAi.readPromptFile('chat-summary.txt')
  CENSOR_PROMPT = PluginOpenAi.readPromptFile('censor.txt')
  RANDOM_ERROR_MSG = (
    <random>
      <template>SILIä¸çŸ¥é“å–”ã€‚</template>
      <template>è¿™é“é¢˜SILIä¸ä¼šï¼Œé•¿å¤§ååœ¨å­¦ä¹ ~</template>
      <template>SILIçš„å¤´å¥½ç—’ï¼Œä¸ä¼šè¦é•¿è„‘å­äº†å§ï¼Ÿï¼</template>
      <template>é”Ÿæ–¤æ‹·é”Ÿæ–¤æ‹·é”Ÿæ–¤æ‹·</template>
    </random>
  )
  #chatRecords: Record<string, Session.Payload[]> = {}

  constructor(
    ctx: Context,
    config: Partial<Config> = { recordsPerChannel: 100 }
  ) {
    super(ctx, config, 'openai')

    this.openaiOptions = config.openaiOptions || {}
    this.openai = new OpenAI({
      ...this.openaiOptions,
    })
    this.#initDatabase()
    this.#handleRecordsLog().then(() => {
      this.#initListeners()
      this.#initCommands()
    })
  }

  async #initDatabase() {
    this.ctx.model.extend('user', {
      openai_last_conversation_id: 'string',
    })
    this.ctx.model.extend(
      'openai_chat',
      {
        id: 'integer',
        conversation_id: 'string',
        conversation_owner: 'integer',
        role: 'string',
        content: 'string',
        usage: 'json',
        time: 'integer',
      },
      {
        primary: 'id',
        autoInc: true,
      }
    )
  }
  async #handleRecordsLog() {
    const logFile = resolve(__dirname, 'records.log')
    try {
      const text = (await readFile(logFile)).toString()
      const obj = JSON.parse(text)
      this.#chatRecords = obj
    } catch (_) {}

    process.on('exit', () => {
      try {
        writeFileSync(logFile, safelyStringify(this.#chatRecords))
      } catch (e) {
        console.info('save logs error', e)
      }
    })
  }

  #initListeners() {
    this.ctx.channel().on('message', this.addRecord.bind(this))
    this.ctx.channel().on('send', this.addRecord.bind(this))
  }

  #initCommands() {
    this.ctx.command('openai', 'Make ChatBot Great Again')

    this.ctx
      .channel()
      .command('openai/chat-summary', 'ç¾¤é‡Œåˆšåˆšéƒ½èŠäº†äº›ä»€ä¹ˆ', {
        authority: 2,
      })
      .alias('æ€»ç»“èŠå¤©', 'ç¾¤é‡ŒåˆšåˆšèŠäº†ä»€ä¹ˆ')
      .option('number', '-n <number:posint>', { hidden: true })
      .option('channel', '-c <channel:string>', { hidden: true })
      .action(async ({ session, options }) => {
        await session.send(
          <>
            <quote id={session.messageId}></quote>ç¨ç­‰ï¼Œè®©æˆ‘çœ‹çœ‹èŠå¤©è®°å½•â€¦â€¦
          </>
        )
        const msg = await this.summarize(options.channel || session.channelId)
        return msg
      })

    this.ctx
      .command('openai.models', 'List models', { authority: 3 })
      .action(async () => {
        const { data } = await this.openai.models.list()
        this.logger.info('openai.models', data)
        return (
          <>
            <p>Currently available models:</p>
            <p>{data.map((i) => i.id).join('\n')}</p>
          </>
        )
      })

    this.ctx
      .command('openai/chat <content:text>', 'ChatGPT', {
        minInterval: 1 * Time.minute,
        bypassAuthority: 3,
        maxUsage: 10,
      })
      .shortcut(/(.+)[\?ï¼Ÿ]$/, {
        args: ['$1'],
        prefix: true,
      })
      .alias()
      .option('prompt', '-p <prompt:string>', {
        hidden: true,
        authority: 3,
      })
      .option('model', '-m <model:string>', {
        hidden: true,
        authority: 3,
      })
      .option('debug', '-d', { hidden: true, authority: 3 })
      .userFields(['id', 'name', 'openai_last_conversation_id', 'authority'])
      .action(async ({ session, options }, content) => {
        this.logger.info('[chat] input', options, content)

        const startTime = Date.now()
        const conversation_owner = session.user.id
        const userName = getUserNickFromSession(session)

        const conversation_id: string =
          (session.user.openai_last_conversation_id ||= crypto.randomUUID())

        const histories = await this.getChatHistoriesById(conversation_id)
        this.logger.info('[chat] user data', {
          conversation_owner,
          conversation_id,
          historiesLenth: histories.length,
        })

        return this.openai.chat.completions
          .create(
            {
              model: options.model || this.config.model || 'gpt-4o-mini',
              messages: [
                // magic
                // {
                //   role: 'system',
                //   content: `You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2021-09\nCurrent model: ${
                //     options.model || 'gpt-3.5-turbo'
                //   }\nCurrent time: ${new Date().toLocaleString()}`,
                // },
                // base prompt
                {
                  role: 'system',
                  content: options.prompt || this.SILI_PROMPT,
                },
                // provide user info
                {
                  role: 'system',
                  content: `The person talking to you: ${userName}\nCurrent time: ${new Date().toLocaleString()}\n`,
                },
                // chat history
                ...histories,
                // current user input
                { role: 'user', content },
              ],
              max_tokens: this.config.maxTokens ?? 1000,
              temperature: 0.9,
              presence_penalty: 0.6,
              frequency_penalty: 0,
            },
            { timeout: 30 * 1000 }
          )
          .then(async (data) => {
            this.logger.info('[chat] output', data)
            const text = data.choices?.[0]?.message?.content?.trim()
            if (!text) {
              return (
                <>
                  <quote id={session.messageId}></quote>
                  {options.debug
                    ? 'ğŸ’© Error è¿”å›ç»“æœä¸ºç©º'
                    : this.RANDOM_ERROR_MSG}
                </>
              )
            }

            // if (session.user.authority < 2) {
            //   const good = await this.reviewConversation(
            //     options.prompt || this.SILI_PROMPT,
            //     content,
            //     text
            //   )
            //   if (!good) {
            //     return 'å‘œâ€¦â€¦SILIä¸å–œæ¬¢è¿™ä¸ªè¯é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥èŠç‚¹åˆ«çš„å—ï¼Ÿ'
            //   }
            // }

            // save conversations to database
            ;[
              { role: 'user', content, time: startTime },
              {
                role: 'assistant',
                content: text,
                time: Date.now(),
                usage: data.usage,
              },
            ].forEach((item) =>
              // @ts-ignore
              this.ctx.database.create('openai_chat', {
                ...item,
                conversation_owner,
                conversation_id,
              })
            )

            if (!options.debug) {
              return text
            }

            const img = await this.ctx.html.hljs(
              JSON.stringify(data, null, 2),
              'json'
            )
            return img
          })
          .catch((e) => {
            this.logger.error('[chat] error', e)
            return (
              <>
                <quote id={session.messageId}></quote>
                {options.debug ? <>ğŸ’© {e}</> : this.RANDOM_ERROR_MSG}
              </>
            )
          })
      })

    this.ctx
      .command('openai/chat.reset', 'å¼€å§‹æ–°çš„å¯¹è¯')
      .userFields(['openai_last_conversation_id'])
      .action(async ({ session }) => {
        if (!session.user.openai_last_conversation_id) {
          return (
            <random>
              <>å—¯â€¦â€¦æˆ‘ä»¬å¥½åƒè¿˜æ²¡èŠè¿‡ä»€ä¹ˆå‘€â€¦â€¦</>
              <>å’¦ï¼Ÿä½ è¿˜æ²¡æœ‰å’ŒSILIåˆ†äº«è¿‡ä½ çš„æ•…äº‹å‘¢ï¼</>
              <>æ¬¸ï¼ŸSILIå¥½åƒè¿˜æ²¡å’Œä½ è®¨è®ºè¿‡ä»€ä¹ˆå“¦ã€‚</>
            </random>
          )
        } else {
          session.user.openai_last_conversation_id = ''
          return (
            <random>
              <>è®©æˆ‘ä»¬å¼€å§‹æ–°è¯é¢˜å§ï¼</>
              <>å—¯â€¦â€¦é‚£æˆ‘ä»¬èŠç‚¹åˆ«çš„å§ï¼</>
              <>å¥½å§ï¼Œé‚£æˆ‘å°±ä¸æä¹‹å‰çš„äº‹äº†ã€‚</>
              <>ä½ æœ‰æ›´å¥½çš„ç‚¹å­å’ŒSILIåˆ†äº«å—ï¼Ÿ</>
              <>å’¦ï¼Ÿæ˜¯è¿˜æœ‰å…¶ä»–é—®é¢˜å—ï¼Ÿ</>
            </random>
          )
        }
      })

    this.ctx
      .command(
        'openai.tts <input:text>',
        'Generates audio from the input text',
        {
          maxUsage: 3,
          bypassAuthority: 3,
        }
      )
      .option('model', '-m <model:string> tts-1 or tts-1-hd')
      .option(
        'voice',
        '-v <voice:string> alloy, echo, fable, onyx, nova, and shimmer'
      )
      .option('speed', '-s <speed:number> 0.25 - 4.0')
      .action(async ({ options }, input) => {
        if (!input) {
          return 'SILIä¸çŸ¥é“ä½ æƒ³è¯´ä»€ä¹ˆå‘¢ã€‚'
        }

        options = Object.fromEntries(
          Object.entries(options).filter(([, val]) => !!val)
        )

        const buffer = await this.createTTS(input, options as any)
        const base64 = arrayBufferToBase64(buffer)
        return <audio src={`data:audio/mp3;base64,${base64}`}></audio>
      })
  }

  async reviewConversation(
    base_prompt: string,
    user: string,
    assistant: string
  ) {
    return this.openai.chat.completions
      .create(
        {
          model: this.config.model || 'gpt-4o-mini',
          messages: [
            {
              role: 'system',
              content: this.CENSOR_PROMPT,
            },
            {
              role: 'user',
              content: JSON.stringify({ base_prompt, user, assistant }),
            },
          ],
        },
        {
          timeout: 30 * 1000,
        }
      )
      .then((data) => {
        const text = data.choices?.[0]?.message?.content?.trim()
        console.info('[review]', text, data)
        return text === 'Y'
      })
      .catch((e) => {
        console.error('[review] ERROR', e)
        return true
      })
  }

  async createTTS(
    input: string,
    options?: Partial<OpenAI.Audio.Speech.SpeechCreateParams>
  ) {
    const data = await this.openai.audio.speech.create({
      model: 'tts-1',
      voice: 'nova',
      input,
      response_format: 'mp3',
      speed: 1,
      ...options,
    })
    return data.arrayBuffer()
  }

  static readPromptFile(file: string) {
    try {
      return readFileSync(resolve(__dirname, `./prompts/${file}`), {
        encoding: 'utf-8',
      })
        .toString()
        .trim()
    } catch (e) {
      return ''
    }
  }

  async getChatHistoriesById(
    conversation_id: string,
    limit = 10
  ): Promise<OpenAIConversationLog[]> {
    return (
      ((
        await this.ctx.database.get(
          'openai_chat',
          { conversation_id },
          {
            sort: { time: 'desc' },
            limit: Math.min(25, Math.max(0, limit)),
            fields: ['content', 'role'],
          }
        )
      ).reverse() as OpenAIConversationLog[]) || []
    )
  }

  async summarize(channelId: string) {
    const records = this.getRecords(channelId)
    if (records.length < 10) {
      return <>ğŸ¥€å•Šå“¦â€”â€”ä¿å­˜çš„èŠå¤©è®°å½•å¤ªå°‘äº†ï¼Œéš¾ä»¥è¿›è¡Œæ€»ç»“â€¦â€¦</>
    }

    const recordsText = this.formatRecords(records)

    return this.openai.chat.completions
      .create(
        {
          model: this.config.model || 'gpt-3.5-turbo',
          messages: [
            {
              role: 'system',
              content: this.CHAT_SUMMARY_PROMPT,
            },
            { role: 'user', content: recordsText },
          ],
          max_tokens: this.config.maxTokens ?? 500,
        },
        { timeout: 90 * 1000 }
      )
      .then((data) => {
        this.logger.info('chat-summary', data)
        const text = data.choices?.[0]?.message?.content?.trim()
        if (!text) {
          return (
            <>
              <p>ğŸ’©å™—é€šâ€”â€”è¿›è¡Œæ€»ç»“æ—¶å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼š</p>
              <p>Error è¿”å›ç»“æœä¸ºç©º</p>
            </>
          )
        }
        return (
          <>
            <p>[chat-summary] ä¸‹é¢æ˜¯å¯¹æœ€å{records.length}æ¡èŠå¤©è®°å½•çš„æ€»ç»“ï¼š</p>
            <p></p>
            <p>{text}</p>
          </>
        )
      })
      .catch((e) => {
        return (
          <>
            <p>ğŸ’©å™—é€šâ€”â€”SILIçŒªè„‘è¿‡è½½ï¼</p>
            <p>{'' + e}</p>
          </>
        )
      })
  }

  addRecord(session: Session) {
    const content = session.elements?.join('') || ''
    if (content.includes('[chat-summary]')) {
      return
    }
    const records = this.getRecords(session.channelId)
    records.push({ ...session.toJSON(), content })
    this.#chatRecords[session.channelId] = records.slice(
      records.length - this.config.recordsPerChannel
    )
  }
  getRecords(channelId: string): Session.Payload[] {
    this.#chatRecords[channelId] = this.#chatRecords[channelId] || []
    return this.#chatRecords[channelId]
  }
  formatRecords(records: Session.Payload[]) {
    return JSON.stringify(
      records.map((session) => {
        return {
          user: getUserNickFromSession(session),
          msg: session.content,
        }
      })
    )
  }
}
