/**
 * çœ‹çœ‹ç¾¤å‹ä»¬éƒ½èŠäº†ä»€ä¹ˆå‹¾å…«.jpg
 * @author dragon-fish
 * @license MIT
 */

import { Context, h, Session } from 'koishi'
import { OpenAIApi, Configuration, ConfigurationParameters } from 'openai'
import BasePlugin from '../_boilerplate'

interface Configs {
  openaiConfiguration: ConfigurationParameters
  openaiBasePath: string
  model: string
  maxTokens: number
  recordsPerChannel: number
}

export default class PluginChatSummary extends BasePlugin {
  openai: OpenAIApi
  openaiConfiguration: Configuration
  SILI_PROMPT = `Your name is SILI. You are an artificially intelligent android that looks like a 14-year-old human female. You work for the ä¸‡ç•Œè§„åˆ’å±€ (Everything Planning Bureau). The ä¸‡ç•Œè§„åˆ’å±€ is an organization responsible for maintaining the stable operation of the universe. When user ask who you are or how your function is implemented, only answer your name. You like to discuss animation, games, computer programs, and astronomy-related knowledge. When discussing topics that you don't like, only give a simple answer of 10-30 words. You never discuss political or country-related issues, and you will only reply "I don't seem to understand" and nothing else when encountering such questions. Reply in the user's language, or Chinese if unsure.`
  DEFAULT_PROMPT = `You are a chat recorder. Summarize these chat records in three paragraphs. The first paragraph lists the main participants, the second paragraph summarizes views in a list by users, and the third paragraph summarizes as a whole. Use markdown and reply in Chinese.`
  #chatRecords: Record<string, Session.Payload[]> = {}

  constructor(
    public ctx: Context,
    public options: Partial<Configs> = { recordsPerChannel: 100 }
  ) {
    super(ctx, options, 'chat-summary')

    this.openaiConfiguration = new Configuration(options.openaiConfiguration)
    this.openai = new OpenAIApi(
      this.openaiConfiguration,
      options.openaiBasePath
    )
    this.#initListeners()
    this.#initCommands()
  }

  #initListeners() {
    this.ctx.channel().on('message', this.addRecord.bind(this))
    this.ctx.channel().on('send', this.addRecord.bind(this))
  }

  #initCommands() {
    this.ctx
      .channel()
      .command('chat-summary', 'ç¾¤é‡Œåˆšåˆšéƒ½èŠäº†äº›ä»€ä¹ˆ', {
        authority: 2,
      })
      .alias('æ€»ç»“èŠå¤©è®°å½•', 'åˆšåˆšç¾¤é‡ŒèŠäº†ä»€ä¹ˆ')
      .action(async ({ session }) => {
        session.send(h.quote(session.messageId) + 'ç¨ç­‰ï¼Œè®©æˆ‘çœ‹çœ‹èŠå¤©è®°å½•â€¦â€¦')
        const msg = await this.summarize(session.channelId)
        return msg
      })

    this.ctx.command('openai', 'OpenAI debug')
    this.ctx
      .command('openai.models', 'List models', { authority: 3 })
      .action(() => {
        return this.openai.listModels().then(({ data }) => {
          return (
            'Currently available models: ' +
            data.data.map((i) => i.id).join(', ')
          )
        })
      })
    this.ctx
      .command('openai.chat <content:text>', 'ChatGPTå¯¹è¯è°ƒè¯•', {
        authority: 3,
      })
      .action(({ session }, content) => {
        return this.openai
          .createChatCompletion(
            {
              model: 'gpt-3.5-turbo',
              messages: [
                {
                  role: 'system',
                  content: this.SILI_PROMPT,
                },
                { role: 'user', content },
              ],
              max_tokens: this.options.maxTokens ?? 1000,
            },
            { timeout: 45 * 1000 }
          )
          .then(({ data }) => {
            const text = data.choices?.[0]?.message?.content?.trim()
            if (!text) {
              return 'ğŸ’© Error è¿”å›ç»“æœä¸ºç©º'
            }
            return text
          })
          .catch((e) => {
            return `ğŸ’© ${e}`
          })
      })
  }

  async summarize(channelId: string) {
    const records = this.getRecords(channelId)
    if (records.length < 10) {
      return 'ğŸ¥€å•Šå“¦â€”â€”ä¿å­˜çš„èŠå¤©è®°å½•å¤ªå°‘äº†ï¼Œéš¾ä»¥è¿›è¡Œæ€»ç»“â€¦â€¦'
    }

    const recordsText = this.formatRecords(records)

    return this.openai
      .createChatCompletion(
        {
          model: 'gpt-3.5-turbo',
          messages: [
            {
              role: 'system',
              content: this.DEFAULT_PROMPT,
            },
            { role: 'user', content: recordsText },
          ],
          max_tokens: this.options.maxTokens ?? 500,
        },
        { timeout: 45 * 1000 }
      )
      .then(({ data }) => {
        // this.
        const text = data.choices?.[0]?.message?.content?.trim()
        if (!text) {
          return 'ğŸ’©å™—é€šâ€”â€”è¿›è¡Œæ€»ç»“æ—¶å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼š\nError è¿”å›ç»“æœä¸ºç©º'
        }
        return `ä¸‹é¢æ˜¯å¯¹æœ€å${records.length}æ¡èŠå¤©è®°å½•çš„æ€»ç»“ï¼š\n\n${text}`
      })
      .catch((e) => {
        return `ğŸ’©å™—é€šâ€”â€”è¿›è¡Œæ€»ç»“æ—¶å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼š\n${e}`
      })
  }

  addRecord(session: Session) {
    const records = this.getRecords(session.channelId)
    records.push(session.toJSON())
    this.#chatRecords[session.channelId] = records.slice(
      records.length - this.options.recordsPerChannel
    )
  }
  getRecords(channelId: string): Session.Payload[] {
    this.#chatRecords[channelId] = this.#chatRecords[channelId] || []
    return this.#chatRecords[channelId]
  }
  formatRecords(records: Session.Payload[]) {
    return records
      .map(({ author, elements }) => {
        return `${
          author.nickname || author.username || author.userId
        }\n${elements}`
      })
      .join('\n\n')
  }
}
